{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Example 2: Cost Explosion Diagnosis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Javihaus/agents_observability_bootcamp/blob/main/chapter_01_diagnosing_agent_failures/examples/example_02_cost_explosion_diagnosis.ipynb)\n",
    "\n",
    "**Instructor demonstration** - Students follow along without running code\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Demonstrate how multi-agent systems experience exponential cost growth through:\n",
    "- Redundant LLM calls\n",
    "- Lack of caching\n",
    "- Retry loops without validation\n",
    "- Over-specified prompts\n",
    "\n",
    "**Key lesson**: Small inefficiencies compound to massive costs in production.\n",
    "\n",
    "---\n",
    "\n",
    "## Scenario\n",
    "\n",
    "**Customer Support Multi-Agent System**\n",
    "- Agent 1: Intent Classifier (determines customer request type)\n",
    "- Agent 2: Information Retriever (fetches relevant docs)\n",
    "- Agent 3: Response Generator (creates customer response)\n",
    "\n",
    "**Version A**: Naive implementation (no caching, full context every call)\n",
    "**Version B**: Optimized implementation (caching, context compression)\n",
    "\n",
    "**Hypothesis**: Version A will cost 3-5x more than Version B for identical functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q langchain==0.1.0 langchain-anthropic==0.1.1 anthropic==0.18.1\n",
    "!pip install -q python-dotenv pandas matplotlib\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import time\n",
    "\n",
    "# Get API key (instructor's key)\n",
    "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cost-tracker"
   },
   "source": [
    "## Cost Tracking Infrastructure\n",
    "\n",
    "We'll track every LLM call to measure cumulative costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tracker-class"
   },
   "outputs": [],
   "source": [
    "class CostTracker:\n",
    "    \"\"\"Track LLM API costs across multiple agent calls.\"\"\"\n",
    "    \n",
    "    # Claude Sonnet 4 pricing (per million tokens)\n",
    "    INPUT_COST_PER_MILLION = 3.0\n",
    "    OUTPUT_COST_PER_MILLION = 15.0\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.calls = []\n",
    "        \n",
    "    def track_call(self, agent_name: str, input_tokens: int, output_tokens: int):\n",
    "        \"\"\"Record a single LLM call.\"\"\"\n",
    "        input_cost = (input_tokens / 1_000_000) * self.INPUT_COST_PER_MILLION\n",
    "        output_cost = (output_tokens / 1_000_000) * self.OUTPUT_COST_PER_MILLION\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        self.calls.append({\n",
    "            'agent': agent_name,\n",
    "            'input_tokens': input_tokens,\n",
    "            'output_tokens': output_tokens,\n",
    "            'input_cost': input_cost,\n",
    "            'output_cost': output_cost,\n",
    "            'total_cost': total_cost\n",
    "        })\n",
    "        \n",
    "    def get_total_cost(self) -> float:\n",
    "        \"\"\"Calculate cumulative cost across all calls.\"\"\"\n",
    "        return sum(call['total_cost'] for call in self.calls)\n",
    "    \n",
    "    def get_cost_by_agent(self) -> Dict[str, float]:\n",
    "        \"\"\"Calculate cost breakdown by agent.\"\"\"\n",
    "        agent_costs = {}\n",
    "        for call in self.calls:\n",
    "            agent = call['agent']\n",
    "            if agent not in agent_costs:\n",
    "                agent_costs[agent] = 0\n",
    "            agent_costs[agent] += call['total_cost']\n",
    "        return agent_costs\n",
    "    \n",
    "    def get_summary_df(self) -> pd.DataFrame:\n",
    "        \"\"\"Return DataFrame with all calls.\"\"\"\n",
    "        return pd.DataFrame(self.calls)\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print cost summary.\"\"\"\n",
    "        total = self.get_total_cost()\n",
    "        by_agent = self.get_cost_by_agent()\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"COST SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nTotal calls: {len(self.calls)}\")\n",
    "        print(f\"Total cost: ${total:.6f}\\n\")\n",
    "        print(\"Cost by agent:\")\n",
    "        for agent, cost in sorted(by_agent.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {agent}: ${cost:.6f}\")\n",
    "\n",
    "print(\"CostTracker class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample-data"
   },
   "source": [
    "## Sample Customer Queries\n",
    "\n",
    "We'll process 5 customer support tickets to compare costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "queries"
   },
   "outputs": [],
   "source": [
    "# Sample customer support queries\n",
    "customer_queries = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'query': 'I forgot my password and the reset email is not arriving. Please help!',\n",
    "        'expected_intent': 'account_access'\n",
    "    },\n",
    "    {\n",
    "        'id': 2,\n",
    "        'query': 'Your product charged my credit card twice for the same order. I need a refund.',\n",
    "        'expected_intent': 'billing_issue'\n",
    "    },\n",
    "    {\n",
    "        'id': 3,\n",
    "        'query': 'How do I export my data to CSV format? I cannot find the option.',\n",
    "        'expected_intent': 'feature_question'\n",
    "    },\n",
    "    {\n",
    "        'id': 4,\n",
    "        'query': 'The mobile app keeps crashing when I try to upload photos.',\n",
    "        'expected_intent': 'technical_issue'\n",
    "    },\n",
    "    {\n",
    "        'id': 5,\n",
    "        'query': 'I want to cancel my subscription and delete my account permanently.',\n",
    "        'expected_intent': 'account_cancellation'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(customer_queries)} sample queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "version-a-header"
   },
   "source": [
    "## Version A: Naive Implementation (High Cost)\n",
    "\n",
    "This version has common anti-patterns:\n",
    "- No caching (repeats identical calls)\n",
    "- Full context in every prompt\n",
    "- No token usage optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "version-a-agents"
   },
   "outputs": [],
   "source": [
    "# Initialize LLM and tracker for Version A\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    anthropic_api_key=ANTHROPIC_API_KEY,\n",
    "    max_tokens=300,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "tracker_a = CostTracker()\n",
    "\n",
    "# Knowledge base (will be included in EVERY prompt in naive version)\n",
    "knowledge_base = \"\"\"COMPANY KNOWLEDGE BASE:\n",
    "\n",
    "Account Access Issues:\n",
    "- Password reset emails may take up to 10 minutes to arrive\n",
    "- Check spam folder for reset emails\n",
    "- Alternative: Reset via SMS to registered phone number\n",
    "- Contact support if issue persists after 24 hours\n",
    "\n",
    "Billing Issues:\n",
    "- Duplicate charges are automatically refunded within 3-5 business days\n",
    "- Check bank statement for pending reversals\n",
    "- Contact billing@company.com for immediate assistance\n",
    "- Include transaction IDs in refund requests\n",
    "\n",
    "Feature Questions:\n",
    "- CSV export: Dashboard → Reports → Export dropdown → Select CSV\n",
    "- Available in Pro and Enterprise plans only\n",
    "- Free users can upgrade or export to PDF\n",
    "- Tutorial: help.company.com/export-data\n",
    "\n",
    "Technical Issues:\n",
    "- Mobile app crashes: Clear app cache, reinstall if needed\n",
    "- Photo upload: Ensure file size < 10MB, JPG/PNG only\n",
    "- Try web version as temporary workaround\n",
    "- Report bugs: support@company.com with device info\n",
    "\n",
    "Account Cancellation:\n",
    "- Cancel anytime: Settings → Subscription → Cancel\n",
    "- Data deletion: Account → Privacy → Delete account\n",
    "- Warning: Deletion is permanent and irreversible\n",
    "- Export data before deletion if needed\n",
    "\"\"\"\n",
    "\n",
    "print(\"Version A initialized\")\n",
    "print(f\"Knowledge base size: {len(knowledge_base)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "version-a-run"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"VERSION A: NAIVE IMPLEMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "version_a_responses = []\n",
    "\n",
    "for query_data in customer_queries:\n",
    "    query_id = query_data['id']\n",
    "    query_text = query_data['query']\n",
    "    \n",
    "    print(f\"\\n--- Processing Query {query_id} ---\")\n",
    "    print(f\"Customer: {query_text}\")\n",
    "    \n",
    "    # Agent 1: Intent Classifier (INCLUDES FULL KNOWLEDGE BASE - wasteful!)\n",
    "    intent_prompt = f\"\"\"{knowledge_base}\n",
    "\n",
    "Customer query: {query_text}\n",
    "\n",
    "Classify the intent as one of: account_access, billing_issue, feature_question, technical_issue, account_cancellation\n",
    "\n",
    "Respond with just the intent category.\"\"\"\n",
    "    \n",
    "    intent_messages = [\n",
    "        SystemMessage(content=\"You are an intent classification agent.\"),\n",
    "        HumanMessage(content=intent_prompt)\n",
    "    ]\n",
    "    \n",
    "    intent_response = llm.invoke(intent_messages)\n",
    "    \n",
    "    # Track tokens (simulated - in real implementation, use response metadata)\n",
    "    intent_input_tokens = len(intent_prompt.split()) * 1.3  # Rough approximation\n",
    "    intent_output_tokens = len(intent_response.content.split()) * 1.3\n",
    "    tracker_a.track_call(\"Intent Classifier\", int(intent_input_tokens), int(intent_output_tokens))\n",
    "    \n",
    "    intent = intent_response.content.strip()\n",
    "    print(f\"Intent: {intent}\")\n",
    "    \n",
    "    # Agent 2: Information Retriever (ALSO INCLUDES FULL KNOWLEDGE BASE - redundant!)\n",
    "    retrieval_prompt = f\"\"\"{knowledge_base}\n",
    "\n",
    "Customer query: {query_text}\n",
    "Intent: {intent}\n",
    "\n",
    "Extract the relevant information from the knowledge base for this query.\"\"\"\n",
    "    \n",
    "    retrieval_messages = [\n",
    "        SystemMessage(content=\"You are an information retrieval agent.\"),\n",
    "        HumanMessage(content=retrieval_prompt)\n",
    "    ]\n",
    "    \n",
    "    retrieval_response = llm.invoke(retrieval_messages)\n",
    "    \n",
    "    retrieval_input_tokens = len(retrieval_prompt.split()) * 1.3\n",
    "    retrieval_output_tokens = len(retrieval_response.content.split()) * 1.3\n",
    "    tracker_a.track_call(\"Information Retriever\", int(retrieval_input_tokens), int(retrieval_output_tokens))\n",
    "    \n",
    "    # Agent 3: Response Generator (AGAIN WITH FULL KNOWLEDGE BASE!)\n",
    "    response_prompt = f\"\"\"{knowledge_base}\n",
    "\n",
    "Customer query: {query_text}\n",
    "Intent: {intent}\n",
    "Relevant information: {retrieval_response.content}\n",
    "\n",
    "Generate a helpful, professional customer support response.\"\"\"\n",
    "    \n",
    "    response_messages = [\n",
    "        SystemMessage(content=\"You are a customer support response agent.\"),\n",
    "        HumanMessage(content=response_prompt)\n",
    "    ]\n",
    "    \n",
    "    final_response = llm.invoke(response_messages)\n",
    "    \n",
    "    response_input_tokens = len(response_prompt.split()) * 1.3\n",
    "    response_output_tokens = len(final_response.content.split()) * 1.3\n",
    "    tracker_a.track_call(\"Response Generator\", int(response_input_tokens), int(response_output_tokens))\n",
    "    \n",
    "    version_a_responses.append(final_response.content)\n",
    "    print(f\"\\nResponse: {final_response.content[:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "tracker_a.print_summary()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "version-b-header"
   },
   "source": [
    "## Version B: Optimized Implementation (Low Cost)\n",
    "\n",
    "This version implements cost optimizations:\n",
    "- Caching of intent classification\n",
    "- Only include relevant knowledge base sections\n",
    "- Compressed context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "version-b-agents"
   },
   "outputs": [],
   "source": [
    "# Initialize tracker for Version B\n",
    "tracker_b = CostTracker()\n",
    "\n",
    "# Knowledge base split by category (for targeted retrieval)\n",
    "kb_sections = {\n",
    "    'account_access': \"\"\"Account Access Issues:\n",
    "- Password reset emails may take up to 10 minutes\n",
    "- Check spam folder\n",
    "- Alternative: SMS reset\n",
    "- Contact support if issue persists after 24 hours\"\"\",\n",
    "    \n",
    "    'billing_issue': \"\"\"Billing Issues:\n",
    "- Duplicate charges refunded within 3-5 business days\n",
    "- Check for pending reversals\n",
    "- Contact billing@company.com with transaction IDs\"\"\",\n",
    "    \n",
    "    'feature_question': \"\"\"Feature Questions:\n",
    "- CSV export: Dashboard → Reports → Export → CSV\n",
    "- Pro/Enterprise only\n",
    "- Tutorial: help.company.com/export-data\"\"\",\n",
    "    \n",
    "    'technical_issue': \"\"\"Technical Issues:\n",
    "- Clear cache, reinstall app\n",
    "- Photos: <10MB, JPG/PNG only\n",
    "- Try web version\n",
    "- Report bugs: support@company.com\"\"\",\n",
    "    \n",
    "    'account_cancellation': \"\"\"Account Cancellation:\n",
    "- Cancel: Settings → Subscription → Cancel\n",
    "- Delete: Account → Privacy → Delete account\n",
    "- Warning: Permanent, irreversible\n",
    "- Export data first if needed\"\"\"\n",
    "}\n",
    "\n",
    "# Simple cache for identical queries\n",
    "intent_cache = {}\n",
    "\n",
    "print(\"Version B initialized\")\n",
    "print(\"Optimizations: Caching, targeted retrieval, context compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "version-b-run"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"VERSION B: OPTIMIZED IMPLEMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "version_b_responses = []\n",
    "\n",
    "for query_data in customer_queries:\n",
    "    query_id = query_data['id']\n",
    "    query_text = query_data['query']\n",
    "    \n",
    "    print(f\"\\n--- Processing Query {query_id} ---\")\n",
    "    print(f\"Customer: {query_text}\")\n",
    "    \n",
    "    # Agent 1: Intent Classifier (NO knowledge base, just classification)\n",
    "    # Check cache first\n",
    "    if query_text in intent_cache:\n",
    "        intent = intent_cache[query_text]\n",
    "        print(f\"Intent (CACHED): {intent}\")\n",
    "        # No LLM call needed - zero cost!\n",
    "    else:\n",
    "        intent_prompt = f\"\"\"Classify this customer query into one of these categories:\n",
    "account_access, billing_issue, feature_question, technical_issue, account_cancellation\n",
    "\n",
    "Query: {query_text}\n",
    "\n",
    "Respond with just the category name.\"\"\"\n",
    "        \n",
    "        intent_messages = [\n",
    "            SystemMessage(content=\"You are an intent classification agent.\"),\n",
    "            HumanMessage(content=intent_prompt)\n",
    "        ]\n",
    "        \n",
    "        intent_response = llm.invoke(intent_messages)\n",
    "        intent = intent_response.content.strip()\n",
    "        \n",
    "        # Cache result\n",
    "        intent_cache[query_text] = intent\n",
    "        \n",
    "        # Track tokens\n",
    "        intent_input_tokens = len(intent_prompt.split()) * 1.3\n",
    "        intent_output_tokens = len(intent_response.content.split()) * 1.3\n",
    "        tracker_b.track_call(\"Intent Classifier\", int(intent_input_tokens), int(intent_output_tokens))\n",
    "        \n",
    "        print(f\"Intent: {intent}\")\n",
    "    \n",
    "    # Agent 2: Information Retriever (ONLY relevant KB section)\n",
    "    relevant_kb = kb_sections.get(intent, \"\")\n",
    "    \n",
    "    retrieval_prompt = f\"\"\"Knowledge base:\n",
    "{relevant_kb}\n",
    "\n",
    "Query: {query_text}\n",
    "\n",
    "Extract relevant info.\"\"\"\n",
    "    \n",
    "    retrieval_messages = [\n",
    "        SystemMessage(content=\"Extract relevant info.\"),\n",
    "        HumanMessage(content=retrieval_prompt)\n",
    "    ]\n",
    "    \n",
    "    retrieval_response = llm.invoke(retrieval_messages)\n",
    "    \n",
    "    retrieval_input_tokens = len(retrieval_prompt.split()) * 1.3\n",
    "    retrieval_output_tokens = len(retrieval_response.content.split()) * 1.3\n",
    "    tracker_b.track_call(\"Information Retriever\", int(retrieval_input_tokens), int(retrieval_output_tokens))\n",
    "    \n",
    "    # Agent 3: Response Generator (compressed context)\n",
    "    response_prompt = f\"\"\"Query: {query_text}\n",
    "Info: {retrieval_response.content}\n",
    "\n",
    "Generate professional support response.\"\"\"\n",
    "    \n",
    "    response_messages = [\n",
    "        SystemMessage(content=\"You are a customer support agent.\"),\n",
    "        HumanMessage(content=response_prompt)\n",
    "    ]\n",
    "    \n",
    "    final_response = llm.invoke(response_messages)\n",
    "    \n",
    "    response_input_tokens = len(response_prompt.split()) * 1.3\n",
    "    response_output_tokens = len(final_response.content.split()) * 1.3\n",
    "    tracker_b.track_call(\"Response Generator\", int(response_input_tokens), int(response_output_tokens))\n",
    "    \n",
    "    version_b_responses.append(final_response.content)\n",
    "    print(f\"\\nResponse: {final_response.content[:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "tracker_b.print_summary()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison-header"
   },
   "source": [
    "## Cost Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COST COMPARISON: VERSION A vs VERSION B\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cost_a = tracker_a.get_total_cost()\n",
    "cost_b = tracker_b.get_total_cost()\n",
    "savings = cost_a - cost_b\n",
    "multiplier = cost_a / cost_b if cost_b > 0 else 0\n",
    "\n",
    "print(f\"\\nVersion A (Naive): ${cost_a:.6f}\")\n",
    "print(f\"Version B (Optimized): ${cost_b:.6f}\")\n",
    "print(f\"\\nAbsolute savings: ${savings:.6f}\")\n",
    "print(f\"Cost multiplier: {multiplier:.2f}x\")\n",
    "print(f\"Percentage reduction: {(savings/cost_a)*100:.1f}%\")\n",
    "\n",
    "# Scale to production\n",
    "queries_per_day = 10000\n",
    "monthly_cost_a = cost_a * queries_per_day * 30\n",
    "monthly_cost_b = cost_b * queries_per_day * 30\n",
    "monthly_savings = monthly_cost_a - monthly_cost_b\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRODUCTION COST PROJECTION (10,000 queries/day)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nVersion A: ${monthly_cost_a:,.2f}/month\")\n",
    "print(f\"Version B: ${monthly_cost_b:,.2f}/month\")\n",
    "print(f\"\\nMonthly savings: ${monthly_savings:,.2f}\")\n",
    "print(f\"Annual savings: ${monthly_savings * 12:,.2f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Per-query cost comparison\n",
    "ax1.bar(['Version A\\n(Naive)', 'Version B\\n(Optimized)'], [cost_a, cost_b], color=['red', 'green'])\n",
    "ax1.set_ylabel('Cost per 5 queries ($)')\n",
    "ax1.set_title('Per-Query Cost Comparison')\n",
    "ax1.axhline(y=cost_a, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Monthly cost projection\n",
    "ax2.bar(['Version A\\n(Naive)', 'Version B\\n(Optimized)'], [monthly_cost_a, monthly_cost_b], color=['red', 'green'])\n",
    "ax2.set_ylabel('Monthly Cost ($)')\n",
    "ax2.set_title('Production Cost Projection (10k queries/day)')\n",
    "ax2.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Simple optimizations (caching, context compression, targeted retrieval)\n",
    "can reduce costs by 60-80% with NO functionality loss.\n",
    "\n",
    "Most costly anti-patterns:\n",
    "1. Including full knowledge base in every prompt\n",
    "2. No caching of repeated operations  \n",
    "3. Redundant context across agents\n",
    "\n",
    "These compound in production to massive waste.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructor-notes"
   },
   "source": [
    "---\n",
    "\n",
    "## Instructor Notes\n",
    "\n",
    "### Teaching Strategy\n",
    "\n",
    "**Before running**: Ask students to estimate cost difference\n",
    "- Most underestimate by 50%+\n",
    "- Reality check is powerful motivator\n",
    "\n",
    "**During execution**: Point out anti-patterns\n",
    "- Highlight when full KB is included unnecessarily\n",
    "- Show token counts growing\n",
    "- Emphasize redundancy\n",
    "\n",
    "**After completion**: Scale to production numbers\n",
    "- Monthly costs make impact concrete\n",
    "- Annual savings justify optimization effort\n",
    "\n",
    "### Common Student Questions\n",
    "\n",
    "**Q: Isn't caching just moving the problem?**\n",
    "A: Yes, but cache hits are free. 80% hit rate = 80% cost reduction for that operation.\n",
    "\n",
    "**Q: What about cache invalidation?**\n",
    "A: Valid concern. Chapter 3 covers cache strategies. For now, focus on identifying cost drivers.\n",
    "\n",
    "**Q: Does compression hurt quality?**\n",
    "A: Rarely. Most prompts have unnecessary verbosity. Test quality vs cost tradeoff.\n",
    "\n",
    "**Q: How do we know what to optimize first?**\n",
    "A: Chapter 2 builds monitoring to identify highest-cost agents. Optimize those first.\n",
    "\n",
    "### Time Management\n",
    "\n",
    "- Setup: 2 minutes\n",
    "- Version A demo: 5 minutes\n",
    "- Version B demo: 5 minutes\n",
    "- Comparison analysis: 5 minutes\n",
    "- Discussion: 5 minutes\n",
    "- **Total: 22 minutes**\n",
    "\n",
    "### Variations\n",
    "\n",
    "If time permits:\n",
    "- Show retry loop anti-pattern (3x multiplier)\n",
    "- Demonstrate unbounded recursion\n",
    "- Compare different caching strategies\n",
    "\n",
    "### Transition to Example 3\n",
    "\n",
    "\"We've seen how costs explode. Now let's see why prompts fail unpredictably when you change format...\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
